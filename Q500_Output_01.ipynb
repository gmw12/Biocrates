{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "460b5845",
   "metadata": {},
   "source": [
    "##### Q500 Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d82af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Alignment, Font\n",
    "\n",
    "pd.set_option('display.max_columns', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04c113",
   "metadata": {},
   "source": [
    "## Data file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7c6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_name = \"6030_Q500_Final\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f09be8",
   "metadata": {},
   "source": [
    "## Pick and Load Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5b12e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4982a9c45c9147349a578831d6a5ac8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/greg/Nextcloud/Biocrates/Q500', filename='', title='', show_hidden=False, select_desc=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fc1 = FileChooser('')\n",
    "fc1.show_only_dirs = False\n",
    "display(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6462c483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q500_configuration.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Display selected folder\n",
    "print(fc1.selected_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de37c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "q500_df = pd.read_excel(fc1.selected, \"Analytes\")\n",
    "material_df = pd.read_excel(fc1.selected, \"Materials\")\n",
    "qc_levels_df = pd.read_excel(fc1.selected, \"QC\")\n",
    "\n",
    "# short cuts\n",
    "q500 = q500_df['Analyte']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b502e",
   "metadata": {},
   "source": [
    "## Pick and Load Met_IDQ file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7d2222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5b3bdd13e34e8baed1809e3c823c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/greg/Nextcloud/Biocrates/Q500', filename='', title='', show_hidden=False, select_desc=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fc2 = FileChooser('')\n",
    "fc2.show_only_dirs = False\n",
    "display(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c3c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/greg/Nextcloud/Biocrates/Q500\n",
      "6030 Raw Exported Data 13SEP2022.txt\n"
     ]
    }
   ],
   "source": [
    "# Display selected folder\n",
    "print(fc2.selected_path)\n",
    "print(fc2.selected_filename)\n",
    "\n",
    "# Create Directory for plots\n",
    "path = fc2.selected_path + \"/plots\"\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "   os.makedirs(path)\n",
    "\n",
    "# Create Directory for plots\n",
    "path = fc2.selected_path + \"/preprocessed_plots\"\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "   os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e719feb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/greg/Nextcloud/Biocrates/Q500/6030 Raw Exported Data 13SEP2022.txt has 329 lines\n"
     ]
    }
   ],
   "source": [
    "# read lines from text file\n",
    "with open(fc2.selected, encoding='utf-8', errors='ignore') as inf:\n",
    "    raw_data = inf.readlines()\n",
    "    \n",
    "# the greek mu is used for micro - causes error, replce with u    \n",
    "raw_data = [line.replace('[M]', '[uM]') for line in raw_data]    \n",
    "print(f'{fc2.selected} has {len(raw_data)} lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fcb76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#MetIDQ-Oxygen-DB110-3005 Concentration [uM] NoNormalization  This export contains Metabolism Indicators\\n']\n"
     ]
    }
   ],
   "source": [
    "# get first comment row\n",
    "first_row = raw_data[0].split('\\t')\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column names, and create empty dataframe\n",
    "column_names = raw_data[1].split('\\t')\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# feed lines from text file into dataframe\n",
    "for line in range(2,len(raw_data)):\n",
    "    next_line = raw_data[line].split('\\t')\n",
    "    df.loc[len(df)] = next_line\n",
    "print(f'Data has {df.shape[0]} rows and {df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70e86e",
   "metadata": {},
   "source": [
    "## Clean and separate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove status column, create new dataframe\n",
    "df_clean = df.loc[:, ~df.columns.str.contains('Status', case=False)]\n",
    "df_clean = df_clean.sort_values(['Material', 'Plate Bar Code', 'Sample Type', 'Sample Identification'])\n",
    "print(f'Removed {df.shape[1] - df_clean.shape[1]} status columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223de17-e8ea-40b5-b4d7-2de6748f4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save metabolism indicators\n",
    "df_met_ind = df_clean.iloc[:,(df_clean.columns.get_loc(q500[len(q500)-1])+1):df_clean.shape[1]]\n",
    "\n",
    "#remove metabolism indicators\n",
    "df_clean = df_clean.iloc[:,0:(df_clean.columns.get_loc(q500[len(q500)-1])+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad69051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather sample data and spqc data\n",
    "df_data = df_clean[(df_clean['Plate Bar Code'] != \"\") & \n",
    "                   (~df_clean['Customer Sample Identification'].str.contains('SPQC', case=False)) &\n",
    "                    (~df_clean['Sample Identification'].str.contains('QC', case=False)) \n",
    "                  ]\n",
    "df_spqc = df_clean[df_clean['Customer Sample Identification'].str.contains('SPQC', case=False)]\n",
    "df_qc = df_clean[df_clean['Sample Identification'].str.contains('QC', case=False)]\n",
    "\n",
    "# reset indexes for dataframes\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "df_spqc = df_spqc.reset_index(drop=True)    \n",
    "df_qc = df_qc.reset_index(drop=True)\n",
    "\n",
    "# save copy with LOD\n",
    "raw_clean_df = pd.concat([df_data, df_qc, df_spqc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather LOD, LLOQ, ULOQ data from text file\n",
    "df_lod = df_clean[df_clean['Injection Number'].str.contains('LOD')]\n",
    "df_lloq = df_clean[df_clean['Injection Number'].str.contains('LLOQ')]\n",
    "df_uloq = df_clean[df_clean['Injection Number'].str.contains('ULOQ')]\n",
    "\n",
    "df_lod = df_lod.reset_index(drop=True)\n",
    "df_lloq = df_lloq.reset_index(drop=True)\n",
    "df_uloq = df_uloq.reset_index(drop=True)\n",
    "\n",
    "# drop the first empty columns\n",
    "df_lod = df_lod.replace(\"\", float(\"NaN\"))\n",
    "df_lod = df_lod.dropna(how='all', axis=1)\n",
    "df_lloq = df_lloq.replace(\"\", float(\"NaN\"))\n",
    "df_lloq = df_lloq.dropna(how='all', axis=1)\n",
    "df_uloq = df_uloq.replace(\"\", float(\"NaN\"))\n",
    "df_uloq = df_uloq.dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather material and plate information from data file\n",
    "materials = df_spqc['Material'].unique()\n",
    "plates = df_spqc['Plate Bar Code'].unique()\n",
    "print(f'There are {len(materials)} materials and {len(plates)} plates')\n",
    "\n",
    "#create material abrev. list to be used throughout code\n",
    "material_abr = []\n",
    "for material in materials:\n",
    "    material_abr.append(str(material_df[material_df['Material']==material]['Name'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a4f861",
   "metadata": {},
   "source": [
    "## Data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0205cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check q500 analyte names and order \n",
    "info_columns = 11\n",
    "\n",
    "test_q500 = (q500 == df_data.columns[info_columns:(info_columns+len(q500))])\n",
    "\n",
    "if test_q500.all() == True:\n",
    "    print('Q500 list and order matches data!')\n",
    "else:\n",
    "    print(f'Q500 Analytes mixed up -> {test_q500}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check material config to data \n",
    "if set(df_data['Material'].unique()).issubset(set(material_df['Material'])):\n",
    "    print('All materials from data found in configuration!')\n",
    "else:\n",
    "    print('New material in data, please add to configuration!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c0e4a",
   "metadata": {},
   "source": [
    "## Apply Dilution Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through materials, isolate data, remove LOD string, apply factor, add LOD string, update original data\n",
    "for material in materials:\n",
    "    temp_df = df_data.loc[(df_data['Material']==material), q500]\n",
    "    temp_df = temp_df.apply(pd.to_numeric, errors='coerce')\n",
    "    #replace nan with 0\n",
    "    temp_df = temp_df.fillna(0)\n",
    "    dil_factor = float(material_df[material_df['Material']== material]['Dilution'])\n",
    "    temp_df = temp_df * dil_factor\n",
    "    #replace 0 with nan\n",
    "    temp_df.replace(0, np.nan, inplace=True)\n",
    "    #convert back to string and \n",
    "    temp_df = temp_df.astype(str)\n",
    "    temp_df = temp_df.replace(\"nan\", \"<LOD\", regex=True)\n",
    "    df_data.loc[(df_data['Material']==material), q500] = temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c89be3",
   "metadata": {},
   "source": [
    "## Create Report Table Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b34c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start build of report table\n",
    "df_report = pd.DataFrame(columns = [\"Analyte\"])\n",
    "df_report['Analyte'] = q500\n",
    "\n",
    "# Loop through plates to transfer LOD info\n",
    "for i in range(0, df_lod.shape[0]):#fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "    lod_info = df_lod.iloc[i].values\n",
    "    df_report.insert(df_report.shape[1], lod_info[0], lod_info[1:df_lod.shape[1]], True)  \n",
    "\n",
    "# Transfer LLOQ info from first plate\n",
    "#lloq_info = df_lloq.iloc[0].values\n",
    "lloq_info = df_lloq.iloc[:,1:df_lloq.shape[1]].fillna(0)\n",
    "lloq_info = lloq_info.apply(pd.to_numeric).max(axis='rows').values\n",
    "df_report.insert(df_report.shape[1], \"Lowest CS (uM)\", lloq_info, True) \n",
    "\n",
    "# Transfer ULOQ info from first plate\n",
    "#uloq_info = df_uloq.iloc[0].values\n",
    "uloq_info = df_uloq.iloc[:,1:df_uloq.shape[1]].fillna(0)\n",
    "uloq_info = uloq_info.apply(pd.to_numeric).max(axis='rows').values\n",
    "df_report.insert(df_report.shape[1], \"Higest CS (uM)\", uloq_info, True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d78241",
   "metadata": {},
   "source": [
    "## Replace <LOD with LOD value from plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ad2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fixed_LOD = False\n",
    "\n",
    "# make sure LOD values read same\n",
    "df_spqc[q500] = df_spqc[q500].replace(regex = [\".*LOD\"], value=\"<LOD\")\n",
    "df_data[q500] = df_data[q500].replace(regex = [\".*LOD\"], value=\"<LOD\")\n",
    "df_qc[q500] = df_qc[q500].replace(regex = [\".*LOD\"], value=\"<LOD\")\n",
    "\n",
    "if use_fixed_LOD:\n",
    "    # Fixed LOD - use the single number analyte\n",
    "    # Loop through bile acids, plates\n",
    "    # one LOD per bile acid and plate, LOD same for different materials\n",
    "    for q in q500:\n",
    "        for plate in plates:\n",
    "            new_lod = df_report[df_report['Analyte']==q].filter(like=plate.replace(\"-\", \"/\")).values[0][0]\n",
    "            #replace LOD in spqc\n",
    "            df_spqc.loc[(df_spqc['Plate Bar Code']==plate) & \n",
    "                        (df_spqc[q].str.contains('LOD')), q] = new_lod\n",
    "            #replace LOD in data\n",
    "            df_data.loc[(df_data['Plate Bar Code']==plate) & \n",
    "                        (df_data[q].str.contains('LOD')), q] = new_lod\n",
    "            #replace LOD in qc\n",
    "            df_qc.loc[(df_qc['Plate Bar Code']==plate) &\n",
    "                      (df_qc[q].str.contains('LOD')), q] = new_lod\n",
    "        \n",
    "else:  \n",
    "    # impute with value LOD * (random number between 0-1)\n",
    "    # create list of random numbers between 0-1, list has seed so will always impute the set the same way\n",
    "    random.seed(1234)\n",
    "    rand_list = [random.random() for i in range(100000)]\n",
    "    rand_count = 0\n",
    "\n",
    "    for q in q500:\n",
    "        print(q)\n",
    "        #search through spqc data\n",
    "        for i in range(df_spqc.shape[0]):\n",
    "            if df_spqc[q][i]=='<LOD':\n",
    "                lod_material = df_spqc['Material'][i]\n",
    "                lod_plate = df_spqc['Plate Bar Code'][i]\n",
    "                new_lod = df_report[df_report['Analyte']==q].filter(like=lod_plate.replace(\"-\", \"/\")).values[0][0]\n",
    "                df_spqc[q][i]=float(new_lod) * rand_list[rand_count]\n",
    "                rand_count +=1\n",
    "        #search through data\n",
    "        for i in range(df_data.shape[0]):\n",
    "            if df_data[q][i]=='<LOD':\n",
    "                lod_material = df_data['Material'][i]\n",
    "                lod_plate = df_data['Plate Bar Code'][i]\n",
    "                new_lod = df_report[df_report['Analyte']==q].filter(like=lod_plate.replace(\"-\", \"/\")).values[0][0]\n",
    "                df_data[q][i]=float(new_lod) * rand_list[rand_count]\n",
    "                rand_count +=1\n",
    "        #search through spqc data\n",
    "        for i in range(df_qc.shape[0]):\n",
    "            if df_qc[q][i]=='<LOD':\n",
    "                lod_material = df_qc['Material'][i]\n",
    "                lod_plate = df_qc['Plate Bar Code'][i]\n",
    "                new_lod = df_report[df_report['Analyte']==q].filter(like=lod_plate.replace(\"-\", \"/\")).values[0][0]\n",
    "                df_qc[q][i]=float(new_lod) * rand_list[rand_count]\n",
    "                rand_count +=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415e47f-cbba-4cb4-b280-b7990b6f671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spqc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b4892-ddcf-494f-84c9-f3fca3151aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, i, lod_material, lod_plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48b7a9-cea4-4aa4-a068-8917acf55043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spqc['Plate Bar Code'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac02954-e754-49ad-9d26-04206b0f2ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd4fae-c13b-40f9-b9f4-47c5899fb9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report[df_report['Analyte']==q].filter(like=lod_plate.replace(\"-\", \"/\")).values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6f021-7127-4eed-9fde-0b689c9dd4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc996f-0e0c-480c-97cb-01076c427377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc350f-252d-4eea-bb05-384614b1d524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e627b-7a12-452c-8053-694a500b0977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d3ad3-9553-45fe-bfdb-1e28e366d1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3c36e-661d-4ee6-b6d4-b92e93412464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895394a-b9ca-4901-a22a-843454344375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a36369-03db-41e2-a36d-a0977c65e40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ef753-9e53-4423-bfb1-8943f0967178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e1f99-d87a-404f-b581-27a6bfb3e6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936e437-e60f-481a-af4d-117a6f16d721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b1e998f",
   "metadata": {},
   "source": [
    "## Create report tables with SPQC Avg, and %CV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c98c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through materials and create a new dataframe with above report template and new avg and %cv calculations\n",
    "temp_df = df_report.copy()\n",
    "for material in materials:\n",
    "\n",
    "    calc_df = df_spqc.loc[(df_spqc[\"Material\"] == material), ba]\n",
    "    calc_df = calc_df.apply(pd.to_numeric)\n",
    "    material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "    temp_df[\"Average \" + material_abr + \" SPQC(uM)\"] = np.round(calc_df.mean().values, 3)\n",
    "    temp_df[\"%CV \" + material_abr + \" SPQC(uM)\"] = np.round(calc_df.std().values/calc_df.mean().values*100, 3)\n",
    "\n",
    "df_report_combined = temp_df\n",
    "print(f'Created combined report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec670350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates indvidual report dataframes for each material\n",
    "# loop through materials and create a new dataframe with above report template and new avg and %cv calculations\n",
    "for material in materials:\n",
    "    temp_df = df_report.copy()\n",
    "\n",
    "    calc_df = df_spqc.loc[(df_spqc[\"Material\"] == material), ba]\n",
    "    calc_df = calc_df.apply(pd.to_numeric)\n",
    "    material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "    temp_df[\"Average \" + material_abr + \" SPQC(uM)\"] = np.round(calc_df.mean().values, 3)\n",
    "    temp_df[\"%CV \" + material_abr + \" SPQC(uM)\"] = np.round(calc_df.std().values/calc_df.mean().values*100, 3)\n",
    "\n",
    "    globals()['df_report_' + material_abr] = temp_df\n",
    "    print(f'Created report for {material_abr}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57b0ae",
   "metadata": {},
   "source": [
    "## Create data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recombine data and spqc's\n",
    "temp_df = pd.concat([df_data, df_spqc])\n",
    "\n",
    "# loop through materials and create a new dataframe\n",
    "for material in materials:\n",
    "    material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "    globals()['df_data_' + material_abr] = temp_df[temp_df['Material'] == material]\n",
    "    print(f'Created data table for {material_abr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e061f4ff",
   "metadata": {},
   "source": [
    "## Creat QC Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e29a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start build of report table\n",
    "df_qc_report = pd.DataFrame(columns = [\"Bile Acid\", \"Abbreviation\"])\n",
    "df_qc_report['Bile Acid'] = ba_df['Name']\n",
    "df_qc_report['Abbreviation'] = ba_df['Abbreviation']\n",
    "\n",
    "qc_levels = ['QC1', 'QC2', 'QC3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05344e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through qc levels \n",
    "for qc_level in qc_levels:\n",
    "    # gather expected value\n",
    "    df_qc_report[qc_level + ' Level (uM)'] = qc_levels_df[qc_levels_df['Expected values']==qc_level][ba].values[0]\n",
    "    \n",
    "    # gather qc data by plate, report uM and accuracy\n",
    "    for plate in plates:\n",
    "        temp_df = df_qc.loc[(df_qc['Plate Bar Code'] == plate) &\n",
    "                   (df_qc['Sample Identification'].str.contains(qc_level)), ba]\n",
    "        temp_df = temp_df.apply(pd.to_numeric)\n",
    "        df_qc_report[qc_level + ' ' + plate + ' Mean (uM)'] = temp_df.mean().values\n",
    "        df_qc_report[qc_level + ' ' + plate + ' Accuracy'] =  round(\n",
    "            df_qc_report[qc_level + ' ' + plate + ' Mean (uM)'] / df_qc_report[qc_level + ' Level (uM)'] * 100, 1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d12549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create summary report without uM Mean values\n",
    "df_qc_report_summary = df_qc_report[df_qc_report.columns.drop(list(df_qc_report.filter(regex='Mean')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da7d70",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ff99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spqc_filter = True\n",
    "lod_filter = True\n",
    "\n",
    "spqc_limit = 30\n",
    "lod_limit = 0.5\n",
    "\n",
    "#create copy unfiltered dataframe for filtered data\n",
    "# loop through materials and create a new dataframe\n",
    "for material in materials: \n",
    "    material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "    globals()['df_data_' + material_abr + '_filtered'] = globals()['df_data_' + material_abr].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76065293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns with SPQC %CV > Limit\n",
    "if spqc_filter:\n",
    "    # loop through materials and create a new dataframe\n",
    "    for material in materials:  \n",
    "        material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "        temp_df = globals()['df_data_' + material_abr + '_filtered'].copy()\n",
    "        # loop through bile acids to check CV\n",
    "        for b in ba:\n",
    "            cv = df_report_combined.loc[df_report_combined['Abbreviation']==b, \n",
    "                                        (\"%CV \" + material_abr + \" SPQC(uM)\")].values\n",
    "            if ((cv > spqc_limit) & (b in temp_df.columns)):\n",
    "                temp_df.drop(b, axis=1, inplace = True)\n",
    "        globals()['df_data_' + material_abr + \"_filtered\"] = temp_df\n",
    "        print(\"Created data SPQC Filtered table for \" + \n",
    "              f\"{material_abr}, dropped {globals()['df_data_' + material_abr].shape[1]-temp_df.shape[1]}\")       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns with > X% (decimal) missing values (LOD)\n",
    "\n",
    "if lod_filter:\n",
    "    # force LOD text to always read same\n",
    "    raw_clean_df[ba] = raw_clean_df[ba].replace(regex = [\".*LOD\"], value=\"<LOD\")\n",
    "\n",
    "    # loop through materials and create a new dataframe\n",
    "    for material in materials:   \n",
    "        material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "        lod_df = raw_clean_df[raw_clean_df['Material']==material].copy()\n",
    "        temp_df = globals()['df_data_' + material_abr + '_filtered'].copy()\n",
    "        for b in ba:\n",
    "            if sum(lod_df[b]==\"<LOD\") > (lod_df.shape[0] * lod_limit ):\n",
    "                try:\n",
    "                    temp_df.drop(b, axis=1, inplace=True)\n",
    "                except:\n",
    "                    print(f\"{b} Already dropped\")\n",
    "\n",
    "        print((f\"Created data LOD table for {material_abr},\") +\n",
    "               (f\" dropped {globals()['df_data_' + material_abr + '_filtered'].shape[1]-temp_df.shape[1]}\")) \n",
    "        globals()['df_data_' + material_abr + \"_filtered\"] = temp_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c0bc7",
   "metadata": {},
   "source": [
    "## Send data to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0954153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_combined_analysis_summary():\n",
    "    #add combined data report\n",
    "    ws = wb.create_sheet(\"Analysis Summary\")    \n",
    "    for r in dataframe_to_rows(df_report_combined, index=False, header=True):\n",
    "        ws.append(r)\n",
    "    align = Alignment(wrap_text=True, horizontal='center')\n",
    "    ft = Font(bold=True)\n",
    "    for row in ws['A1':'AA1']:\n",
    "        for cell in row:\n",
    "            cell.alignment = align\n",
    "            cell.font = ft\n",
    "    ws.column_dimensions['A'].width = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef908d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indiv_analysis_summary():\n",
    "    #add individual material data reports\n",
    "    for material in materials:\n",
    "        material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "        temp_df = globals()['df_report_' + material_abr]\n",
    "        sheet_name = f\"QC Summary {material_abr}\"\n",
    "        ws = wb.create_sheet(sheet_name)    \n",
    "        for r in dataframe_to_rows(temp_df, index=False, header=True):\n",
    "            ws.append(r)\n",
    "        align = Alignment(wrap_text=True, horizontal='center')\n",
    "        ft = Font(bold=True)\n",
    "        for row in ws['A1':'AA1']:\n",
    "            for cell in row:\n",
    "                cell.alignment = align\n",
    "                cell.font = ft\n",
    "        ws.column_dimensions['A'].width = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e85003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_combined_qc_summary():\n",
    "    #add qc report to excel        \n",
    "    ws = wb.create_sheet(\"QC Summary\")    \n",
    "    for r in dataframe_to_rows(df_qc_report, index=False, header=True):\n",
    "        ws.append(r)\n",
    "    align = Alignment(wrap_text=True, horizontal='center')\n",
    "    ft = Font(bold=True)\n",
    "    for row in ws['A1':'AA1']:\n",
    "        for cell in row:\n",
    "            cell.alignment = align\n",
    "            cell.font = ft\n",
    "    ws.column_dimensions['A'].width = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data():\n",
    "    #add material data to excel\n",
    "    for material in materials:\n",
    "        material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "        temp_df = globals()['df_data_' + material_abr]\n",
    "        sheet_name = f\"{material_abr}\"           \n",
    "        ws = wb.create_sheet(sheet_name)    \n",
    "        for r in dataframe_to_rows(temp_df, index=False, header=True):\n",
    "            ws.append(r)\n",
    "        align = Alignment(wrap_text=True, horizontal='center')\n",
    "        ft = Font(bold=True)\n",
    "        for row in ws['A1':'AA1']:\n",
    "            for cell in row:\n",
    "                cell.alignment = align\n",
    "                cell.font = ft\n",
    "        #ws.column_dimensions['A'].width = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_preprocessed():\n",
    "    #add filtered/preprocessed data to excel\n",
    "    for material in materials:\n",
    "        material_abr = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "        temp_df = globals()['df_data_' + material_abr + \"_filtered\"]\n",
    "        sheet_name = f\"{material_abr} Preprocessed\"\n",
    "        ws = wb.create_sheet(sheet_name)    \n",
    "        for r in dataframe_to_rows(temp_df, index=False, header=True):\n",
    "            ws.append(r)\n",
    "        align = Alignment(wrap_text=True, horizontal='center')\n",
    "        ft = Font(bold=True)\n",
    "        for row in ws['A1':'AA1']:\n",
    "            for cell in row:\n",
    "                cell.alignment = align\n",
    "                cell.font = ft\n",
    "        #ws.column_dimensions['A'].width = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save excel to path of original raw data\n",
    "path = f'{fc2.selected_path}/{final_data_name}.xlsx'\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Biocrates Export\"\n",
    "for line in raw_data:\n",
    "    next_line = line.split('\\t')\n",
    "    ws.append(next_line)\n",
    "\n",
    "   \n",
    "add_combined_analysis_summary()   \n",
    "add_combined_qc_summary()\n",
    "add_data()\n",
    "add_preprocessed()\n",
    "\n",
    "wb.save(path)\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14af74",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scree_plot(pca, pca_material, ax=None, show_title=False):\n",
    "    sns.set_style('whitegrid')\n",
    "    ax = ax\n",
    "    # Bar plot of explained_variance\n",
    "    #fig = plt.figure(figsize = (8,8))\n",
    "    ax.bar(\n",
    "        range(1,len(pca.explained_variance_)+1),\n",
    "        pca.explained_variance_\n",
    "        )\n",
    "\n",
    "    ax.plot(range(1,len(pca.explained_variance_ )+1),\n",
    "             np.cumsum(pca.explained_variance_),c='red',\n",
    "             label='Cumulative Explained Variance')\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(False)\n",
    "    ax.set_xlabel('Number of components')\n",
    "    ax.set_ylabel('Explained variance (eignenvalues)')\n",
    "    if show_title:\n",
    "        ax.set_title(f'{pca_material} Scree plot', fontsize = 16)\n",
    "\n",
    "    #ax.savefig(f'{fc2.selected_path}/{pca_material}_ScreePlot.png')\n",
    "    return(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1260e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_plot(pca_df, pca_material, ax=None, show_title=True):\n",
    "    sns.set_style('whitegrid')\n",
    "    #fig = plt.figure(figsize = (8,8))\n",
    "    #ax = fig.add_subplot(1,1,1) \n",
    "    ax=ax\n",
    "    ax.set_xlabel('PCA1', fontsize = 12)\n",
    "    ax.set_ylabel('PCA2', fontsize = 12)\n",
    "    if show_title:\n",
    "        ax.set_title(f'{pca_material} PCA plot', fontsize = 16)\n",
    "    targets = ['Sample', 'SPQC']\n",
    "    colors = ['r', 'b']\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = pca_df['target'] == target\n",
    "        ax.scatter(pca_df.loc[indicesToKeep, 'PC1']\n",
    "                   , pca_df.loc[indicesToKeep, 'PC2']\n",
    "                   , c = color\n",
    "                   , s = 50)\n",
    "    ax.legend(targets)\n",
    "\n",
    "    return(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf915bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_plot(pca_material, xs, ys, feature_names, ax=None, show_title=False):\n",
    "    # Plot the loadings on a scatterplot\n",
    "    #ax = fig.add_subplot(1,1,1) \n",
    "    sns.set_style('whitegrid')\n",
    "    ax = ax            \n",
    "    for i, varnames in enumerate(feature_names):\n",
    "        ax.scatter(xs[i], ys[i], s=200)\n",
    "        ax.arrow(\n",
    "            0, 0, # coordinates of arrow base\n",
    "            xs[i], # length of the arrow along x\n",
    "            ys[i], # length of the arrow along y\n",
    "            color='grey', \n",
    "            head_width=0.01\n",
    "            )\n",
    "        ax.text(xs[i], ys[i], varnames)\n",
    "\n",
    "    # Define the axes\n",
    "    xticks = np.linspace(-0.8, 0.8, num=5)\n",
    "    yticks = np.linspace(-0.8, 0.8, num=5)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_xlabel('PC1', fontsize=12)\n",
    "    ax.set_ylabel('PC2', fontsize=12)\n",
    "    ax.grid(False)\n",
    "    if show_title:\n",
    "        ax.set_title(f'{pca_material} Loading Plot', fontsize = 16)\n",
    "    return(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(use_preprocessed = False, scale_pca=False):\n",
    "    #loop through materials - calc and plot pca's\n",
    "    \n",
    "    if use_preprocessed:\n",
    "        plot_path = f'{fc2.selected_path}/preprocessed_plots/'\n",
    "    else:\n",
    "        plot_path = f'{fc2.selected_path}/plots/'   \n",
    "        \n",
    "    for material in materials:\n",
    "        pca_material = str(material_df[material_df['Material']==material]['Name'].values[0])\n",
    "\n",
    "        if use_preprocessed:\n",
    "            data_for_pca = globals()['df_data_' + pca_material + '_filtered'] \n",
    "            plot_prefix = f'{pca_material}_Preprocessed'\n",
    "        else:\n",
    "            data_for_pca = globals()['df_data_' + pca_material] \n",
    "            plot_prefix = f'{pca_material}'\n",
    "\n",
    "        #get list of analytes incase using filtered data\n",
    "        pca_ba = list(set(ba.values) & set(data_for_pca.columns))\n",
    "        pca_ba.sort()\n",
    "\n",
    "        #clearly identify sample and spqc\n",
    "        X = data_for_pca[pca_ba].apply(pd.to_numeric, errors = 'coerce')\n",
    "        y = data_for_pca['Customer Sample Identification']\n",
    "        y = y.str.replace(\".*SPQC\", \"SPQC\", regex=True)\n",
    "        y = y.str.replace(\"^((?!SPQC).)*$\", \"Sample\", regex=True)\n",
    "\n",
    "        # log data for PCA\n",
    "        X = np.log2(X)\n",
    "        # scale PCA\n",
    "        if scale_pca:\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # compute PCA\n",
    "        pca = PCA(n_components=5) \n",
    "        pca_features = pca.fit_transform(X)\n",
    "        pca_df = pd.DataFrame(\n",
    "            data=pca_features, \n",
    "            columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
    "        pca_df['target'] = y.values\n",
    "\n",
    "        # Principal components correlation coefficients\n",
    "        loadings = pca.components_\n",
    "\n",
    "        # Number of features before PCA\n",
    "        n_features = pca.n_features_\n",
    "\n",
    "        # Feature names before PCA\n",
    "        feature_names = pca_ba\n",
    "\n",
    "        # PC names\n",
    "        pc_list = [f'PC{i}' for i in list(range(1, n_features + 1))]\n",
    "\n",
    "        # Match PC names to loadings\n",
    "        pc_loadings = dict(zip(pc_list, loadings))\n",
    "\n",
    "        # Matrix of corr coefs between feature names and PCs\n",
    "        load_all_df = pd.DataFrame.from_dict(pc_loadings)\n",
    "        load_all_df['feature_names'] = feature_names\n",
    "        load_all_df = load_all_df.set_index('feature_names')\n",
    "\n",
    "        #get top 3 loadings from PC1 and PC2\n",
    "        sorted_load = load_all_df\n",
    "        sorted_load['PC1_abs'] = abs(sorted_load['PC1'])\n",
    "        sorted_load['PC2_abs'] = abs(sorted_load['PC2'])\n",
    "\n",
    "        sorted_load = sorted_load.sort_values(by=['PC1_abs'], ascending=False)\n",
    "        PC1_load = sorted_load.head(3)\n",
    "\n",
    "        sorted_load = sorted_load.sort_values(by=['PC2_abs'], ascending=False)\n",
    "        PC2_load = sorted_load.head(3)\n",
    "\n",
    "        load_top_df = pd.concat([PC1_load, PC2_load]).drop_duplicates()    \n",
    "\n",
    "\n",
    "        # combined plot for report - Scree + PCA + Loading\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,7))\n",
    "        scree_plot(pca, pca_material, ax1, show_title = False)\n",
    "        pca_plot(pca_df, pca_material, ax2, show_title = False)\n",
    "        load_plot(pca_material, load_top_df['PC1'].values, load_top_df['PC2'].values, \n",
    "                  load_top_df.index.values, ax3, show_title=False)\n",
    "        fig.subplots_adjust(top=0.85, bottom=0.15, left=0.05, right=0.95)\n",
    "        fig.suptitle(f'{pca_material} - Scree, PCA, and Loading Plot', fontsize = 20)\n",
    "        plt.savefig(f'{plot_path}/{plot_prefix}_combined_plot.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        #save individual plots    \n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(7,7))\n",
    "        scree_plot(pca, pca_material, ax1, show_title = True)\n",
    "        fig.subplots_adjust(top=0.92, bottom=0.08, left=0.1, right=0.9)\n",
    "        plt.savefig(f'{plot_path}/{plot_prefix}_scree.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(7,7))\n",
    "        pca_plot(pca_df, pca_material, ax1, show_title = True)\n",
    "        fig.subplots_adjust(top=0.92, bottom=0.08, left=0.1, right=0.9)\n",
    "        plt.savefig(f'{plot_path}/{plot_prefix}_PCA.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(7,7))\n",
    "        load_plot(pca_material, load_all_df['PC1'].values, load_all_df['PC2'].values, \n",
    "                  load_all_df.index.values, ax1, show_title=True)\n",
    "        fig.subplots_adjust(top=0.92, bottom=0.08, left=0.1, right=0.9)\n",
    "        plt.savefig(f'{plot_path}/{plot_prefix}_load_all_plot.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(7,7))\n",
    "        load_plot(pca_material, load_top_df['PC1'].values, load_top_df['PC2'].values, \n",
    "                  load_top_df.index.values, ax1, show_title=True)\n",
    "        fig.subplots_adjust(top=0.92, bottom=0.08, left=0.1, right=0.9)\n",
    "        plt.savefig(f'{plot_path}//{plot_prefix}_load_top_plot.png')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f996a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(use_preprocessed = False, scale_pca = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(use_preprocessed = True, scale_pca = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65cf23",
   "metadata": {},
   "source": [
    "## SPQC Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4250d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cols = [col for col in df_report_combined.columns if '%CV' in col]\n",
    "temp_df = df_report_combined[cv_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf239b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path = f'{fc2.selected_path}/plots/'\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "bp = ax.boxplot(temp_df, patch_artist = True,\n",
    "                notch ='True', vert = 0)\n",
    "\n",
    "colors = [f'C{i}' for i in range(temp_df.shape[1])]\n",
    "\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "plt.title(\"SPQC %CV\", fontsize=20)\n",
    "y_label = [sub.replace('SPQC(uM)', \"\") for sub in temp_df.columns.values]\n",
    "ax.set_yticklabels(y_label, fontsize=10)\n",
    "ax.get_xaxis().tick_bottom()\n",
    "ax.get_yaxis().tick_left()\n",
    "ax.grid(False)\n",
    "\n",
    "plt.savefig(f'{plot_path}//SPQC_CV.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2d948",
   "metadata": {},
   "source": [
    "## SPQC Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85261d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2_df = pd.DataFrame(columns = [\"Under\", \"Over\"])\n",
    "temp2_df['Under'] = temp_df[(temp_df <= 30)].count()\n",
    "temp2_df['Over'] = temp_df[(temp_df >30)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x = np.arange(temp2_df.shape[0])\n",
    "\n",
    "width=0.4\n",
    "\n",
    "ax.bar(x-.2, temp2_df['Under'], width, color=\"seagreen\")\n",
    "ax.bar(x+.2, temp2_df['Over'], width, color=\"firebrick\")\n",
    "\n",
    "xticks = [sub.replace(' Accuracy', \"\") for sub in temp2_df.index.to_list()]\n",
    "ax.set_xticks(x, xticks)\n",
    "ax.set_xlabel(\"QC\", fontsize=20)\n",
    "ax.set_ylabel(\"Count\", fontsize=20)\n",
    "ax.grid(False)\n",
    "plt.legend(['<30% Accuracy', '>30% Accuracy'])\n",
    "plt.title(\"SPQC Summary\", fontsize=20)\n",
    "plt.savefig(f'{plot_path}//SPQC_Summary.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d06c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585e0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37a43281",
   "metadata": {},
   "source": [
    "## QC Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cols = [col for col in df_qc_report.columns if 'Accuracy' in col]\n",
    "temp_df = df_qc_report[cv_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26817c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path = f'{fc2.selected_path}/plots/'\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "bp = ax.boxplot(temp_df, patch_artist = True,\n",
    "                notch ='True', vert = 0)\n",
    "\n",
    "colors = [f'C{i}' for i in range(temp_df.shape[1])]\n",
    "\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "plt.title(\"QC Accuracy\", fontsize=20)\n",
    "y_label = [sub.replace(' Accuracy', \"\") for sub in temp_df.columns.values]\n",
    "ax.set_yticklabels(y_label, fontsize=10)\n",
    "ax.get_xaxis().tick_bottom()\n",
    "ax.get_yaxis().tick_left()\n",
    "ax.grid(False)\n",
    "\n",
    "plt.savefig(f'{plot_path}//QC_CV.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadaa741",
   "metadata": {},
   "source": [
    "## QC Summary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2_df = pd.DataFrame(columns = [\"Under\", \"Over\"])\n",
    "temp2_df['Under'] = temp_df[(temp_df >= 70) &  (temp_df <= 130)].count()\n",
    "temp2_df['Over'] = temp_df[(temp_df < 70) |  (temp_df > 130)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05338747",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x = np.arange(temp2_df.shape[0])\n",
    "\n",
    "width=0.4\n",
    "\n",
    "ax.bar(x-.2, temp2_df['Under'], width, color=\"seagreen\")\n",
    "ax.bar(x+.2, temp2_df['Over'], width, color=\"firebrick\")\n",
    "\n",
    "xticks = [sub.replace(' Accuracy', \"\") for sub in temp2_df.index.to_list()]\n",
    "ax.set_xticks(x, xticks, rotation=45)\n",
    "ax.set_xlabel(\"QC\", fontsize=20)\n",
    "ax.set_ylabel(\"Count\", fontsize=20)\n",
    "ax.grid(False)\n",
    "plt.legend(['<30% Accuracy', '>30% Accuracy'])\n",
    "plt.title(\"QC Summary\", fontsize=20)\n",
    "plt.savefig(f'{plot_path}//QC_Summary.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47508f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb87c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de5d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67394c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e8e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715ca86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
